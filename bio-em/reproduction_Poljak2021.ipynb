{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.nn as nn\n",
    "from jax import vmap, jit, grad\n",
    "from jax.experimental import optimizers\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.constants import epsilon_0 as eps_0, mu_0, c, pi\n",
    "from scipy.interpolate import interp1d\n",
    "import seaborn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable 64-bit precision in `jax`\n",
    "\n",
    "# jax.config.update('jax_enable_x64', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set context to `seaborn`\n",
    "\n",
    "seaborn.set(style='whitegrid', context='paper', palette='colorblind', font='serif', font_scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high-resolution rendering\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "Z_0 = np.sqrt(mu_0 / eps_0)\n",
    "a = 2e-3\n",
    "N_elem = 61\n",
    "L = 1\n",
    "dx = L / N_elem\n",
    "x = np.arange(0, L+dx/2, dx)\n",
    "I = np.loadtxt('DipolSctGnd025.str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load current over a half-wave dipole antenna for 0.3 GHz frequency\n",
    "\n",
    "f = I[N_elem+1:, 1][0]\n",
    "omega = 2 * pi * f\n",
    "k = omega * np.sqrt(mu_0 * eps_0)\n",
    "I_an = I[N_elem+1:, 2] + 1j * I[N_elem+1:, 3]\n",
    "y = I_an * 1000  # in mA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize spatial current distribution\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.plot(x, np.abs(y), 'b-', lw=3, label='$|I(x)|$')\n",
    "ax.plot(x, np.real(y), 'r-', lw=3, label='$\\Re{[I(x)]}$')\n",
    "ax.plot(x, np.imag(y), 'g-', lw=3, label='$\\Im{[I(x)]}$')\n",
    "ax.set(xlabel='$x$ [m]', ylabel='$I$ [mA]')\n",
    "fig.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finite-step derivative approximation on interpolated function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_diff(fn, h=1e-6):\n",
    "    \"\"\"Forward difference y = np.abs(I_an) * 1000  # in mAapproximation.\"\"\"\n",
    "    def dfn_dx(x):\n",
    "        return (fn(x + h) - fn(x)) / h\n",
    "    return dfn_dx\n",
    "    \n",
    "    \n",
    "def backward_diff(fn, h=1e-6):\n",
    "    \"\"\"Backward difference approximation.\"\"\"\n",
    "    def dfn_dx(x):\n",
    "        return (fn(x) - fn(x - h)) / h\n",
    "    return dfn_dx\n",
    "\n",
    "    \n",
    "def central_diff(fn, h=1e-6):\n",
    "    \"\"\"Central difference approximation.\"\"\"\n",
    "    def dfn_dx(x):\n",
    "        return (fn(x + h) - fn(x - h)) / (2 * h)\n",
    "    return dfn_dx\n",
    "\n",
    "\n",
    "def complex_step_diff(fn, h=1e-6):\n",
    "    \"\"\"Complex-step difference approximation.\n",
    "    \n",
    "    Note: Incompatible with SciPy interpolation module.\n",
    "    \"\"\"\n",
    "    def dfn_dx(x):\n",
    "        return np.imag(fn(x + 1j * h)) / h\n",
    "    return dfn_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quadratic interpolation of current distribution function\n",
    "f = interp1d(x, np.abs(y), kind='quadratic')\n",
    "\n",
    "x_new = np.linspace(x.min(), x.max(), 1001)\n",
    "y_new = f(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean relative percentage error\n",
    "\n",
    "error = np.mean(np.abs(np.abs(y)[1:-1] - f(x)[1:-1]) / np.abs(y)[1:-1]) * 100\n",
    "print(f'relative error = {error:.2e} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize spatial current distribution as calculated and interpolated\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.plot(x, np.abs(y), 'b-', lw=4, label='computed')\n",
    "ax.plot(x_new, y_new, 'r--', lw=4, label='interpolated')\n",
    "ax.set(xlabel='$x$ [m]', ylabel='$I$ [mA]')\n",
    "fig.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finite difference on computed and interpolated data\n",
    "\n",
    "dfdx = np.r_[(forward_diff(f)(x[0]), central_diff(f)(x[1:-1]), backward_diff(f)(x[-1]))]\n",
    "dfdx_new = np.r_[(forward_diff(f)(x_new[0]), central_diff(f)(x_new[1:-1]), backward_diff(f)(x_new[-1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize current gradient distribution as calculated and interpolated\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.plot(x, dfdx, 'b-', lw=4, label='computed')\n",
    "ax.plot(x_new, dfdx_new, 'r--', lw=4, label='interpolated')\n",
    "ax.plot([x[2], x[-2]], [dfdx[2], dfdx[-2]], 'ko', fillstyle='none', markersize=40, markeredgewidth=2.5)\n",
    "ax.set(xlabel='$x$ [m]', ylabel=r'$\\mathrm{d}I$ / $\\mathrm{d}x$ [mA/m]')\n",
    "ax.annotate('', xy=(x[2], dfdx[2] - 0.5), xytext=(x[11], -dfdx[2] - 2), \n",
    "            arrowprops={'facecolor': 'black'})\n",
    "ax.annotate('', xy=(x[-5], dfdx[-2]), xytext=(x[11], -dfdx[2] - 2), \n",
    "            arrowprops={'facecolor': 'black'})\n",
    "ax.text(x[0], -dfdx[0] - 2, 'numeric artifacts',\n",
    "        bbox={'facecolor': 'wheat',\n",
    "              'edgecolor': 'black',\n",
    "              'alpha': 0.5,\n",
    "              'pad': 5})\n",
    "fig.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic differentiation on neural network-based interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = jnp.asarray(x_new).reshape(-1, 1)\n",
    "y_train = jnp.asarray(y_new).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "\n",
    "def init_network_params(sizes, key):\n",
    "    \"\"\"Initialize network parameters.\"\"\"\n",
    "    keys = jax.random.split(key, len(sizes))\n",
    "    def random_layer_params(m, n, key, scale=1e-2):\n",
    "        w_key, b_key = jax.random.split(key)\n",
    "        return (scale * jax.random.normal(w_key, (n, m)),\n",
    "                scale * jax.random.normal(b_key, (n, )))\n",
    "    return [random_layer_params(m, n, key)\n",
    "            for m, n, key in zip(sizes[:-1], sizes[1:], keys)]\n",
    "\n",
    "\n",
    "def forward(params, X):\n",
    "    \"\"\"Forward pass.\"\"\"\n",
    "    output = X\n",
    "    for w, b in params[:-1]:\n",
    "        output = nn.tanh(w @ output + b)\n",
    "    w, b = params[-1]\n",
    "    output = w @ output + b\n",
    "    return output\n",
    "\n",
    "\n",
    "# vectorized mapping of network input, `X`, on `forward` function\n",
    "batch_forward = vmap(forward, in_axes=(None, 0))\n",
    "\n",
    "\n",
    "@jit\n",
    "def loss_fn(params, batch):\n",
    "    \"\"\"Summed square error loss function.\"\"\"\n",
    "    X, y = batch\n",
    "    y_pred = batch_forward(params, X)\n",
    "    return jnp.sum(jnp.square(y_pred - y))\n",
    "\n",
    "\n",
    "# derivative of the loss function\n",
    "grad_fn = jit(grad(loss_fn))\n",
    "\n",
    "\n",
    "@jit\n",
    "def update(step, optim_state, batch):\n",
    "    \"\"\"Return current optimal state of the network.\"\"\"\n",
    "    params = optim_params(optim_state)\n",
    "    grads = grad_fn(params, batch)\n",
    "    optim_state = optim_update(step, grads, optim_state)\n",
    "    return optim_state\n",
    "\n",
    "\n",
    "def data_stream(num_train, num_batches):\n",
    "    \"\"\"Training data random generator.\"\"\"\n",
    "    rng = npr.RandomState(0)\n",
    "    while True:\n",
    "        perm = rng.permutation(num_train)\n",
    "        for i in range(num_batches):\n",
    "            batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
    "            yield x_train[batch_idx], y_train[batch_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set network hyperparameter and train\n",
    "\n",
    "step_size = 1e-3\n",
    "n_epochs = 5e4\n",
    "printout = int(n_epochs / 100.)\n",
    "epochs = np.arange(0, n_epochs+1, step=printout)\n",
    "batch_size = 512\n",
    "momentum_mass = 0.9  # for mvmapntum and adagrad\n",
    "sizes = [1, 128, 256, 128, 1]\n",
    "\n",
    "num_train = x_train.shape[0]\n",
    "num_complete_batches, leftover = divmod(num_train, batch_size)\n",
    "num_batches = num_complete_batches + bool(leftover)\n",
    "\n",
    "batches = data_stream(num_train, num_batches)\n",
    "\n",
    "optim_init, optim_update, optim_params = optimizers.adam(step_size)\n",
    "init_params = init_network_params(sizes, rng)\n",
    "optim_state = optim_init(init_params)\n",
    "itercount = itertools.count()\n",
    "\n",
    "loss_train = []\n",
    "for epoch in trange(n_epochs):\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_batches):\n",
    "        optim_state = update(next(itercount), optim_state, next(batches))\n",
    "    epoch_time = time.time() - start_time\n",
    "    \n",
    "    params = optim_params(optim_state)\n",
    "    if (epoch == 0) or (epoch % printout == (printout - 1)):\n",
    "        loss_train.append(loss_fn(params, (x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize training loss dynamics\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.plot(epochs, loss_train, 'b-', lw=4)\n",
    "ax.set(xlabel='epoch', ylabel='loss', yscale='log');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize spatial current distribution as calculated and fitted\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.plot(x_train.flatten(), y_train.flatten(), 'b-', lw=4, label='computed')\n",
    "ax.plot(x_train.flatten(), batch_forward(params, x_train).flatten(), 'r--', lw=4, label='fitted')\n",
    "ax.set(xlabel='$x$ [m]', ylabel='$I$ [mA]')\n",
    "fig.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def I_an_nn(x):\n",
    "    \"\"\"Current value at specific location, `x`.\n",
    "    \n",
    "    Note: This is single-value wrapper for the forward pass function.\n",
    "    \"\"\"\n",
    "    return forward(params, x)[0]\n",
    "\n",
    "\n",
    "# derivative of the current approximation function\n",
    "grad_I_an_nn = jit(vmap(grad(I_an_nn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize current gradient distribution as calculated and fitted\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.plot(x_new, dfdx_new, 'b-', lw=4, label='computed')\n",
    "ax.plot(x_train, grad_I_an_nn(x_train), 'r--', lw=4, label='fitted')\n",
    "ax.set(xlabel='$x$ [m]', ylabel=r'$\\mathrm{d}I$ / $\\mathrm{d}x$ [mA/m]')\n",
    "fig.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power flow along a wire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute power distribution along the dipole\n",
    "\n",
    "q_points, q_weights = np.polynomial.legendre.leggauss(4)\n",
    "q_points_scaled = dx / 2 * q_points + dx / 2\n",
    "N1 = (1 - q_points) / 2\n",
    "N2 = (1 + q_points) / 2\n",
    "\n",
    "dIdx = grad_I_an_nn(jnp.array(x).reshape(-1, 1)).flatten()\n",
    "V = np.zeros_like(dIdx)\n",
    "for i in range(N_elem):\n",
    "    xx = x[i] + q_points_scaled\n",
    "    dI = dIdx[i] * N1 + dIdx[i+1] * N2\n",
    "    rad = np.sqrt((x - xx[0]) ** 2 + a ** 2)\n",
    "    G = dI[0] * q_weights[0] * np.exp(-1j * k * rad) / rad\n",
    "    rad = np.sqrt((x - xx[1]) ** 2 + a ** 2)\n",
    "    G = G + dI[1] * q_weights[1] * np.exp(-1j * k * rad) / rad\n",
    "    rad = np.sqrt((x - xx[2]) ** 2 + a ** 2)\n",
    "    G = G + dI[2] * q_weights[2] * np.exp(-1j * k * rad) / rad\n",
    "    rad = np.sqrt((x - xx[3]) ** 2 + a ** 2)\n",
    "    G = G + dI[3] * q_weights[3] * np.exp(-1j * k * rad) / rad\n",
    "    V = V + G\n",
    "V = 0.5 * dx * V / (-1j * 4 * pi * omega * eps_0)\n",
    "\n",
    "S = 0.5 * V * np.conj(I_an)\n",
    "P = np.real(S)\n",
    "Q = np.imag(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize power spatial distribution\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.plot(x, P, 'b-', lw=4, label='$P(x)$')\n",
    "ax.plot(x, Q, 'r-', lw=4, label='$Q(x)$')\n",
    "ax.plot(x, np.abs(S), 'g-', lw=4, label='$|S(x)|$')\n",
    "ax.set(xlabel='$x$ [m]', ylabel='power [mW]')\n",
    "fig.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
